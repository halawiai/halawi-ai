# Model Documentation

**Source:** Models configured in `chart/env/dev.yaml` (MODELS environment variable)  
**Last Updated:** November 23, 2025  
**Total Models:** 113

---

## Premium Reasoning Models

High-performance models with full tool support for complex reasoning tasks.

**Premium:** `openai/gpt-oss-120b`, `openai/gpt-oss-20b`, `deepseek-ai/DeepSeek-V3.2-Exp`, `deepseek-ai/DeepSeek-V3.1-Terminus`, `deepseek-ai/DeepSeek-V3.1`, `deepseek-ai/DeepSeek-V3-0324`, `deepseek-ai/DeepSeek-V3`, `deepseek-ai/DeepSeek-R1-0528`, `zai-org/GLM-4.6`, `zai-org/GLM-4.6-FP8`, `zai-org/GLM-4.5-Air`, `moonshotai/Kimi-K2-Instruct-0905`, `moonshotai/Kimi-K2-Instruct`, `Qwen/Qwen3-Coder-480B-A35B-Instruct`, `Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8`, `Qwen/Qwen3-Coder-30B-A3B-Instruct`, `Qwen/Qwen2.5-Coder-32B-Instruct`, `Qwen/Qwen2.5-72B-Instruct`, `Kwaipilot/KAT-Dev`, `deepcogito/cogito-v2-preview-llama-70B`

---

## Text Chat Models

Fast, efficient text-only models without tool support.

**Text:** `Qwen/Qwen3-235B-A22B-Instruct-2507`, `Qwen/Qwen3-235B-A22B-Thinking-2507`, `Qwen/Qwen3-235B-A22B`, `Qwen/Qwen3-235B-A22B-FP8`, `Qwen/Qwen3-Next-80B-A3B-Instruct`, `Qwen/Qwen3-Next-80B-A3B-Thinking`, `Qwen/Qwen3-30B-A3B-Instruct-2507`, `Qwen/Qwen3-30B-A3B-Thinking-2507`, `Qwen/Qwen3-30B-A3B`, `Qwen/Qwen3-32B`, `Qwen/Qwen3-14B`, `Qwen/Qwen3-8B`, `Qwen/Qwen3-4B-Instruct-2507`, `Qwen/Qwen3-4B-Thinking-2507`, `Qwen/QwQ-32B`, `Qwen/QwQ-32B-Preview`, `Qwen/Qwen2.5-7B-Instruct`, `Qwen/Qwen2.5-Coder-7B-Instruct`, `Qwen/Qwen2.5-Coder-7B`, `Qwen/Qwen2.5-Coder-3B-Instruct`, `meta-llama/Llama-3.3-70B-Instruct`, `meta-llama/Llama-3.1-405B-Instruct`, `meta-llama/Llama-3.1-70B-Instruct`, `meta-llama/Llama-3.1-8B-Instruct`, `meta-llama/Llama-3.2-3B-Instruct`, `meta-llama/Llama-3.2-1B-Instruct`, `meta-llama/Meta-Llama-3-70B-Instruct`, `meta-llama/Meta-Llama-3-8B-Instruct`, `meta-llama/Llama-Guard-4-12B`, `deepseek-ai/DeepSeek-R1`, `deepseek-ai/DeepSeek-R1-0528-Qwen3-8B`, `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`, `deepseek-ai/DeepSeek-R1-Distill-Qwen-14B`, `deepseek-ai/DeepSeek-R1-Distill-Qwen-7B`, `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`, `deepseek-ai/DeepSeek-R1-Distill-Llama-70B`, `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`, `deepseek-ai/DeepSeek-Prover-V2-671B`, `zai-org/GLM-4-32B-0414`, `zai-org/GLM-4.5-Air-FP8`, `NousResearch/Hermes-4-405B`, `NousResearch/Hermes-4-70B`, `NousResearch/Hermes-3-Llama-3.1-405B`, `NousResearch/Hermes-3-Llama-3.1-70B`, `NousResearch/Hermes-2-Pro-Llama-3-8B`, `CohereLabs/c4ai-command-a-03-2025`, `CohereLabs/c4ai-command-r-08-2024`, `CohereLabs/c4ai-command-r7b-12-2024`, `CohereLabs/c4ai-command-r7b-arabic-02-2025`, `CohereLabs/command-a-translate-08-2025`, `CohereLabs/aya-expanse-32b`, `CohereLabs/aya-expanse-8b`, `google/gemma-2-9b-it`, `google/gemma-2-2b-it`, `baidu/ERNIE-4.5-300B-A47B-Base-PT`, `baidu/ERNIE-4.5-21B-A3B-PT`, `baidu/ERNIE-4.5-0.3B-PT`, `swiss-ai/Apertus-70B-Instruct-2509`, `swiss-ai/Apertus-8B-Instruct-2509`, `nvidia/Llama-3_1-Nemotron-Ultra-253B-v1`, `MiniMaxAI/MiniMax-M1-80k`, `HuggingFaceTB/SmolLM3-3B`, `baichuan-inc/Baichuan-M2-32B`, `aisingapore/Gemma-SEA-LION-v4-27B-IT`, `arcee-ai/AFM-4.5B`, `alpindale/WizardLM-2-8x22B`, `tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4`, `Sao10K/L3-70B-Euryale-v2.1`, `Sao10K/L3-8B-Stheno-v3.2`, `Sao10K/L3-8B-Lunaris-v1`, `SentientAGI/Dobby-Unhinged-Llama-3.3-70B`, `marin-community/marin-8b-instruct`, `katanemo/Arch-Router-1.5B`, `deepcogito/cogito-v2-preview-llama-405B`, `deepcogito/cogito-v2-preview-llama-109B-MoE`, `deepcogito/cogito-v2-preview-deepseek-671B-MoE`

---

## Vision Models

Models with image understanding capabilities (multimodal support).

**Vision:** `Qwen/Qwen3-VL-235B-A22B-Instruct`, `Qwen/Qwen3-VL-235B-A22B-Thinking`, `Qwen/Qwen2.5-VL-72B-Instruct`, `Qwen/Qwen2.5-VL-32B-Instruct`, `Qwen/Qwen2.5-VL-7B-Instruct`, `meta-llama/Llama-4-Maverick-17B-128E-Instruct`, `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`, `meta-llama/Llama-4-Scout-17B-16E-Instruct`, `zai-org/GLM-4.5V`, `zai-org/GLM-4.1V-9B-Thinking`, `google/gemma-3-27b-it`, `baidu/ERNIE-4.5-VL-424B-A47B-Base-PT`, `baidu/ERNIE-4.5-VL-28B-A3B-PT`, `CohereLabs/command-a-vision-07-2025`, `CohereLabs/command-a-reasoning-08-2025`, `CohereLabs/aya-vision-32b`, `CohereLabs/aya-vision-8b`

---

## Audio Transcription Models

Speech-to-text models for voice input.

**Audio:** *(None currently configured)*

---

## Models by Provider

Models are also categorized by their inference provider (Groq, Hugging Face, Together, Fireworks, etc.). To see models grouped by provider, run:

```bash
OPENAI_BASE_URL=https://router.huggingface.co/v1 OPENAI_API_KEY=your_key \
  npx tsx scripts/categorize-models-by-provider.ts
```

This will show:
- Models grouped by inference provider
- Models grouped by organization (model creator)
- Enabled/disabled status for each model
- Quick reference lists by provider

---

## Notes

- **Model IDs** are exact identifiers from the `MODELS` configuration in `chart/env/dev.yaml`
- **Premium models** are identified by tool support capabilities (function calling, agent workflows)
- **Vision models** are identified by multimodal/image input support (VL suffix, vision in description)
- **Text models** are standard language models without special capabilities
- **Provider information** comes from the HuggingFace Router API (`providers` array)
- Models can be hidden from the UI by setting `"unlisted": true` in the configuration
- Model capabilities (multimodal, supportsTools) are determined from the HuggingFace Router API and can be overridden in the MODELS configuration
- **Filtering:** Use the `/models` page to filter by provider or search by name

---

## How to Update This Documentation

### By Features (Premium/Text/Vision/Audio)

Run the categorization script to regenerate this documentation:

```bash
npx tsx scripts/categorize-models-by-features.ts
```

### By Provider

To generate provider-based categorization:

```bash
OPENAI_BASE_URL=https://router.huggingface.co/v1 OPENAI_API_KEY=your_key \
  npx tsx scripts/categorize-models-by-provider.ts
```

### Manual Updates

Or manually update based on changes to `chart/env/dev.yaml` or `chart/env/prod.yaml`.

---

## Enabling/Disabling Models

See `MODEL_MANAGEMENT.md` for detailed instructions on:
- How to enable/disable models using the `unlisted` flag
- Filtering models by provider in the UI
- Bulk operations and best practices

